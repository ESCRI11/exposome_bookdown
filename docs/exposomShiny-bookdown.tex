% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
  \usepackage{amssymb}
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={exposomeShiny User's Guide},
  pdfauthor={Escribà Montagut, Xavier; González, Juan R.},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\title{exposomeShiny User's Guide}
\author{Escribà Montagut, Xavier; González, Juan R.}
\date{2021-02-22}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{overview}{%
\chapter{Overview}\label{overview}}

\includegraphics[width=0.5\textwidth,height=\textheight]{images/athlete.png}

\includegraphics[width=0.6\textwidth,height=\textheight]{images/logo.png}

exposomeShiny is a data analysis toolbox with the following features:

\begin{itemize}
\tightlist
\item
  Data handling: imputation, LOD, transformation, \ldots{}
\item
  Exposome characterization
\item
  Exposome-wide association analysis
\item
  Multivariate association
\item
  Omic data integration
\item
  Post-omic data analysis: CTD database
\end{itemize}

To do so, exposomeShiny relies on previously existent Bioconductor packages (rexposome, omicRexposome and CTDquerier), it uses them in a seamless way so the final user of exposomShiny can perform the same studies that would conduct using the Bioconductor packages but without writing a single line of code.

\hypertarget{setup}{%
\chapter{Setup}\label{setup}}

\hypertarget{r-rstudio-and-packages-versions}{%
\section{R, RStudio and Packages Versions}\label{r-rstudio-and-packages-versions}}

If the user chooses to install and use exposomeShiny using RStudio instead of Docker, the list of package versions used for the development of the application is provided for stability purposes. When using the Docker version of the application, all of the following is bundled on the image so the user does not have to deal with the installation of any package.

Software:

\begin{longtable}[]{@{}ll@{}}
\toprule
R software & Version\tabularnewline
\midrule
\endhead
R & 4.0.2\tabularnewline
RStudio & 1.4.1103\tabularnewline
\bottomrule
\end{longtable}

R packages:

\begin{longtable}[]{@{}ll@{}}
\toprule
R Packages & Version\tabularnewline
\midrule
\endhead
shiny & 1.5.0\tabularnewline
shinyBS & 0.61\tabularnewline
rexposome & 1.12.2\tabularnewline
omicRexposome & 1.12.0\tabularnewline
MultiDataSet & 1.18.0\tabularnewline
mice & 3.11.0\tabularnewline
DT & 0.16\tabularnewline
ggplot2 & 3.3.2\tabularnewline
data.table & 1.13.2\tabularnewline
truncdist & 1.0\tabularnewline
shinyalert & 2.0.0\tabularnewline
shinydashboard & 0.7.1\tabularnewline
shinyjs & 2.0.0\tabularnewline
TxDb.Hsapiens.UCSC.hg19.knownGene & 3.2.2\tabularnewline
org.Hs.eg.db & 3.12.0\tabularnewline
GenomicRanges & 1.42.0\tabularnewline
CTDquerier & 1.4.3\tabularnewline
shinycssloaders & 1.0.0\tabularnewline
pastecs & 1.3.21\tabularnewline
shinyWidgets & 0.5.4\tabularnewline
clusterProfiler & 3.18.1\tabularnewline
enrichplot & 1.10.2\tabularnewline
ggupset & 0.3.0\tabularnewline
imputeLCMD & 2.0\tabularnewline
pls & 2.7-3\tabularnewline
\bottomrule
\end{longtable}

There are two different ways of setting up and using exposomeShiny

\hypertarget{downloading-the-source-files-installing-the-libraries-and-running-the-application}{%
\section{Downloading the source files, installing the libraries and running the application}\label{downloading-the-source-files-installing-the-libraries-and-running-the-application}}

The user can choose to download the source code of the shiny application and install all the required libraries on their local R installation. Make sure \href{https://cran.r-project.org/bin/windows/Rtools/history.html}{Rtools} is installed to use this method.

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# Set working directory}
\FunctionTok{setwd}\NormalTok{(}\AttributeTok{dir =} \StringTok{"/some/path/"}\NormalTok{)}
      
  \CommentTok{\# Download zip}
\FunctionTok{download.file}\NormalTok{(}\AttributeTok{url =} \StringTok{"https://github.com/isglobal{-}brge/exposomeShiny/archive/master.zip"}\NormalTok{, }\AttributeTok{destfile =} \StringTok{"master.zip"}\NormalTok{)}

  \CommentTok{\# Unzip the .zip to the working directory}
\FunctionTok{unzip}\NormalTok{(}\AttributeTok{zipfile =} \StringTok{"master.zip"}\NormalTok{)}

  \CommentTok{\# Set the working directory inside the downloaded folder}
\FunctionTok{setwd}\NormalTok{(}\AttributeTok{dir =} \StringTok{"/some/path/exposomeShiny{-}master"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now all the source files are downloaded to the location of chose and the working directory moved to the correct folder, to start the project, open the \texttt{Rproj} file by clicking it on the Files explorer of RStudio.

\includegraphics{images/setup1.png}

Once the project is loaded, the file found on the source folder called \texttt{installer.R} has to be sourced and run. This will install the newest versions of the packages required by Exposome Shiny on this R session. To do so, run the following code on the RStudio console.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{source}\NormalTok{(}\StringTok{"installer.R"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This is only needed on the first run, once completed it doesn't need to be done prior to launching the application itself any other time.

Now everything is ready to launch the Shiny application. To do so there a two approaches, one is to open the \texttt{ui.R} or the \texttt{server.R} files that are inside the \texttt{R} folder and press \texttt{Run\ App}.

\includegraphics{images/setup2.png}

Or the other option is to input the following command on the console.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runApp}\NormalTok{(}\StringTok{\textquotesingle{}R\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{pulling-the-official-docker-image-from-dockerhub}{%
\section{Pulling the official Docker image from DockerHub}\label{pulling-the-official-docker-image-from-dockerhub}}

If there's any troubble downloading the required R packages to make exposomeShiny work, there's the option of using Docker. It has the disadvantage of being a little bit difficult to install on a Windows machine, however, it's extremely simple on a Mac OS X / Linux environment. For the Windows users refer to the following links for instructions on how to install Docker and setup you machine to run WSL2 and launch bash commands on Windows \href{https://docs.docker.com/docker-for-windows/install-windows-home/}{1}, \href{https://blog.nillsf.com/index.php/2020/02/17/setting-up-wsl2-windows-terminal-and-oh-my-zsh/}{2}, \href{https://docs.docker.com/docker-for-windows/wsl/}{3}.

To download and launch exposomeShiny, execute the following command on a bash terminal(make sure Docker is running, if not search for the \texttt{Docker\ Desktop} app and launch it).

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{docker}\NormalTok{ run {-}{-}rm {-}p 80:80 brgelab/exposome{-}shiny}
\end{Highlighting}
\end{Shaded}

This command will download the Docker image of exposomeShiny (be aware it weights \textasciitilde{} 3 GB, so if your internet connection is slow it may take a while) and run a container with it. The container will be exposed on the local port 80 and it will render on that port the application itself, so to start using exposomeShiny open your web browser and go to the site

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{localhost}\NormalTok{:80}
\end{Highlighting}
\end{Shaded}

At the beginning it may take some time for the application to render, this is because all the needed R libraries are being loaded, to be sure the container is actually working, take a look at the terminal where you inputed the Docker command, there you will see all the R verbose stating the libraries are being loaded.

Once the user has finished using exposomeShiny, the container needs to be stopped to avoid wasting CPU resources, to do so, input the following command on a bash terminal (the command needs to be inputed on a new bash window):

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{docker}\NormalTok{ container ls}
\end{Highlighting}
\end{Shaded}

This will prompt all the running containers, find the one with the NAMES \texttt{brgelab/exposome-shiny} and copy it's CONTAINER ID, then input the following bash command:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{docker}\NormalTok{ stop xxxxxxxxxxxx}
\end{Highlighting}
\end{Shaded}

Where xxxxxxxxxxxx is the CONTAINER ID.

To run the application again, just enter the first bash command (\texttt{docker\ run\ -\/-rm\ -p\ 80:80\ brgelab/exposome-shiny}), since it has already been downloaded, the application is cached on the computer and it will launch straight away. If the user wants to remove the Docker image from the computer, input the following bash command:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{docker}\NormalTok{ image rm brgelab/exposome{-}shiny}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-sets}{%
\chapter{Data sets}\label{data-sets}}

\hypertarget{exposome-dataset}{%
\section{Exposome dataset}\label{exposome-dataset}}

The exposome is composed of three different files (in \texttt{*.csv} format). Those files are refered inside the Shiny as exposures, description and phenotypes. Their content is the following:

\begin{itemize}
\tightlist
\item
  The \texttt{exposures} file contains the measures of each exposure for all the individuals included on the analysis. It is a matrix-like file having a row per individual and a column per exposures. It must includes a column with the subject's identifier.
\item
  The \texttt{description} file contains a row for each exposure and, at last, defined the families of exposures. Usually, this file incorporates a description of the exposures, the matrix where it was obtained and the units of measurement among others.
\item
  The \texttt{phenotypes} file contains the covariates to be included in the analysis as well as the health outcomes of interest. It contains a row per individual included in the analysis and a column for each covariate and outcome. Moreover, it must include a column with the individual's identifier.
\end{itemize}

A visual representation of the three matrices and how they correlate is the following.

\includegraphics{images/exposome_dataset_struct.png}

Exposures data file example:

\begin{verbatim}
id    bde100  bde138  bde209  PFOA    ...
sub01  2.4665  0.7702  1.6866  2.0075 ...
sub02  0.7799  1.4147  1.2907  1.0153 ...  
sub03 -1.6583 -0.9851 -0.8902 -0.0806 ... 
sub04 -1.0812 -0.6639 -0.2988 -0.4268 ... 
sub05 -0.2842 -0.1518 -1.5291 -0.7365 ... 
...   ...     ...     ...     ...
\end{verbatim}

Description data file example:

\begin{verbatim}
exposure  family  matrix         description
bde100    PBDEs   colostrum       BDE 100 - log10
bde138    PBDEs   colostrum       BDE 138 - log10
bde209    PBDEs   colostrum       BDE 209 - log10
PFOA      PFAS    cord blood      PFOA - log10
PFNA      PFAS    cord blood      PFNA - log10
PFOA      PFAS    maternal serum  PFOA - log10
PFNA      PFAS    maternal serum  PFNA - log10
hg        Metals  cord blood      hg - log 10
Co        Metals  urine           Co (creatinine) - log10
Zn        Metals  urine           Zn (creatinine) - log10
Pb        Metals  urine           Pb (creatinine) - log10
THM       Water   ---             Average total THM uptake - log10
CHCL3     Water   ---             Average Chloroform uptake - log10
BROM      Water   ---             Average Brominated THM uptake - log10
NO2       Air     ---             NO2 levels whole pregnancy- log10
Ben       Air     ---             Benzene levels whole pregnancy- log10
\end{verbatim}

Phenotypes data file example:

\begin{verbatim}
id    asthma   BMI      sex  age  ...
sub01 control  23.2539  boy  4    ...
sub02 asthma   24.4498  girl 5    ...
sub03 asthma   15.2356  boy  4    ...
sub04 control  25.1387  girl 4    ...
sub05 control  22.0477  boy  5    ...
...   ...      ...      ...  ...
\end{verbatim}

\hypertarget{plain-datasets}{%
\section{Plain datasets}\label{plain-datasets}}

If the researcher has gathered all the data on a single file which contains both phenotype and exposure data, this file can be used too. The user interface has a selector for it, more information on the \protect\hyperlink{plain_data}{correspondent section}.

A visual representation of a plain dataset is the following.

\includegraphics{images/plain_tables.png}

Plain dataset example (3 exposures + 2 phenotypes):

\begin{verbatim}
id    bde100  bde138  bde209    asthma   BMI      ...
sub01  2.4665  0.7702  1.6866   control  23.2539  ...
sub02  0.7799  1.4147  1.2907   asthma   24.4498  ...  
sub03 -1.6583 -0.9851 -0.8902   asthma   15.2356  ... 
sub04 -1.0812 -0.6639 -0.2988   control  25.1387  ... 
sub05 -0.2842 -0.1518 -1.5291   control  22.0477  ...
...   ...     ...      ...      ...      ...
\end{verbatim}

\hypertarget{omicsds}{%
\section{Omics dataset}\label{omicsds}}

The omics data inputed to the Shiny must be provided as an \texttt{*.RData}. This file has to contain an ExpressionSet, which is an S4 object. This object is a data container of the Bioconductor toolset.

For further information on ExpressionSet and how to create and manipulate them, please visit the \href{https://www.bioconductor.org/packages/devel/bioc/vignettes/Biobase/inst/doc/ExpressionSetIntroduction.pdf}{official documentation} and this \href{https://kasperdanielhansen.github.io/genbioconductor/html/ExpressionSet.html}{selected vignette}.

\hypertarget{bioconductor-packages}{%
\chapter{Bioconductor packages}\label{bioconductor-packages}}

This Shiny application is a front end support for other Bioconductor packages in order to provide a comfortable environment on to conduct different analysis with those packages. In concrete the packages are \href{https://www.bioconductor.org/packages/release/bioc/html/rexposome.html}{rexposome}, \href{https://bioconductor.org/packages/release/bioc/html/omicRexposome.html}{omicRexposome} and \href{http://www.bioconductor.org/packages/release/bioc/html/CTDquerier.html}{CTDquerier}.

\hypertarget{rexposome}{%
\section{rexposome}\label{rexposome}}

Rexposome is a package that allows to explore the exposome and to perform association analyses between exposures and health outcomes.

\hypertarget{omicrexposome}{%
\section{omicRexposome}\label{omicrexposome}}

OmicRexposome is a package that systematizes the association evaluation between exposures and omic data, taking advantage of MultiDataSet for coordinated data management, rexposome for exposome data definition and limma for association testing. Also to perform data integration mixing exposome and omic data using multi co-inherent analysis (omicade4) and multi-canonical correlation analysis (PMA).

\hypertarget{ctdquerier}{%
\section{CTDquerier}\label{ctdquerier}}

CTDquerier is a package to retrieve and visualize data from the \href{http://ctdbase.org/}{Comparative Toxicogenomics Database}. The downloaded data is formated as DataFrames for further downstream analyses.

\hypertarget{analysis-flowcharts}{%
\chapter{Analysis flowcharts}\label{analysis-flowcharts}}

\hypertarget{exposome-health-analysis}{%
\section{Exposome health analysis}\label{exposome-health-analysis}}

As any user would need to do using the Bioconductor packages (rexposome, omicRexposome and CTDquerier) when performing an analysis using an \texttt{R} script, there is some kind of flow (or pipeline) to follow in order to get to the results, this is also true on exposomeShiny, even though it's a seamless and codeless integration of the packages there's still some need for a flowchart to get the desired results. All the required flowcharts will be detailed with a box flowchart as well as screenshots of exposomeShiny in order to provide extra guidance if needed.

\hypertarget{data-entry}{%
\subsection{Data entry}\label{data-entry}}

\hypertarget{exposome-data}{%
\subsubsection{Exposome data}\label{exposome-data}}

Input the exposures, description and phenotypes files and load them into the application. This files have to be provided as \texttt{csv} or \texttt{txt}, there is a selector on the UI to select the type of separation used, it can be either commas, semicolons or tabs/spaces. Excel files or R objects are not supported as inputs.

\includegraphics{images/analysis1_2.png} Once the tables are read two new main elements will appear, 1) the option to explore the inputted table, using a selector of the table and a button to trigger the visualization; and 2) six input fields will appear on the right side of the file browsers, they are to select the following parameters:

\begin{itemize}
\tightlist
\item
  Column name in the \emph{description} file that contains the exposures
\item
  Column name in the \emph{description} file that contains the families\\
\item
  Column name in the \emph{exposures} file that contains the id's
\item
  Column name in the \emph{phenotypes} file that contains the id's
\item
  The treshold of to select between continuous or factor exposures. More than this number of unique items will be considered as `continuous'
\item
  The encoding to search for limit of detection (LOD) missings. It can be either a number (example: \texttt{-1}) or a string (example: \texttt{LOD}).
\end{itemize}

This is illustrated on the following figure.

\includegraphics{images/analysis1_2_2.png}

Once the fields are completed, please press the \emph{Validate selections} button in order to check if all the parameters allow for a successful load of the exposome dataset, if not, a pop-up will be prompted to the user. In the case that everything is correct, the UI will be updated and a button that reads \emph{Load selected data to analyze it} will appear, by clicking this button the dataset will be loaded and the analysis can begin. The input fields are still visible past this point for the case that the user wants to load a new dataset into the application without restarting it.

\hypertarget{plain_data}{%
\subsubsection{Plain data}\label{plain_data}}

When dealing with a single file that contains the exposures and phenotype data, press the ``My data is contained in a single table'' toggle. This will change the interface to only show one file selector.

\includegraphics{images/plain_table_1.png}

Select a file and press ``Read file information''. This will change the interface to show a multiple selector input, all the available columns will be listed, select the ones which correspond to phenotypes.

\includegraphics{images/plain_table_2.png}

When all the phenotypes are selected, press ``Confirm''. Now the researcher can group the exposures into families, to do so, select them on the table, input the family name on the field ``Family of selected exposures'' and press ``Assign''. All the exposures that have empty ``Family'' fields will be treated as they are their own family.

\includegraphics{images/plain_table_3.png}

Finally, there are two configuration fields:

\begin{itemize}
\tightlist
\item
  The treshold of to select between continuous or factor exposures. More than this number of unique items will be considered as `continuous'
\item
  The encoding to search for limit of detection (LOD) missings. It can be either a number (example: \texttt{-1}) or a string (example: \texttt{LOD}).
\end{itemize}

Be sure to revise them before pressing ``Load data''.

\hypertarget{lod-imputation}{%
\subsection{LOD imputation}\label{lod-imputation}}

\includegraphics{images/analysis1_1.png}

If exposomeShiny detects LODs (limit of detection) on the exposures file, it will prompt the table with the exposures with LOD and double clicking on the desired cell will enable edit mode to input the instrument LOD. There's also the option of selecting ``Random imputation'' on the imputation method in order to imputate with random values (truncated log distribution) instead of LOD/sqrt(2). If the user imputes the LOD missings, the dataset will be imputed and the user will not need to reimport it, the loaded dataset will be updated to have the LOD missings imputed, this can be checked by clicking on the \texttt{!} symbol at the top bar of the application.

\includegraphics{images/analysis1_3.png}

\hypertarget{missing-imputation}{%
\subsection{Missing imputation}\label{missing-imputation}}

\includegraphics{images/analysis2_1.png}

Once the dataset is loaded into the Shiny, look at the ``Missing Data'' tab to check the percentages of missing data for each exposure present.

\includegraphics{images/analysis2_2.png}

To impute the missing values select ``Impute missing values using mice'' (Multiple Imputation by Chained Equations), no other method of imputation is available in the software at the moment. After the process finishes, the expect output should be a new missing data graph where there's no missing of any exposure.

\includegraphics{images/analysis2_3.png} The new imputed exposures set can be downloaded as a \texttt{*.csv} file, please note that the downloaded file just assigns numbers to the \texttt{idnum} column, if the data you are using has different \texttt{idnum} format it's needed to format it properly so that it matches the \texttt{idnum} on the phenotypes input file when inputting it to the Shiny.

\hypertarget{exposures-description}{%
\subsection{Exposures description}\label{exposures-description}}

There's the option of visualizing the main descriptive stats of the exposures dataset, available for quantitative exposure varibables. The descriptive stats (per exposure) included on the table are:

\begin{itemize}
\tightlist
\item
  Number of values
\item
  Number of NULLs
\item
  Number of NAs
\item
  Minimum
\item
  Maximum
\item
  Range of values
\item
  Sum of values
\item
  Median
\item
  Mean
\item
  Standard Error of mean
\item
  0.95 confidence interval of the mean
\item
  Variance
\item
  Standard deviation
\item
  Variance coefficient
\end{itemize}

This table will have the descriptive stats of the loaded dataset, this means that if the user has imputed the missings (remember that after imputing the missings, the imputed dataset becomes active) it will be reflected on the table as it will show 0 NAs.

\includegraphics{images/analysis2_4.png}

\hypertarget{normality-correction}{%
\subsection{Normality correction}\label{normality-correction}}

\includegraphics{images/analysis3_1.png}

Once the dataset is loaded into the Shiny, look at the ``Check Normality'' tab to check which exposures are not normal (Normality = false), this are the results of Shapiro--Wilk testing. By selecting from the table the desired exposure and clicking the ``Plot histogram of selected exposure'', as the label of the button implies, a histogram of the selected exposure from the table can be seen.

\includegraphics{images/analysis3_2.png}

There is also the option of visualizing the histogram for the implemented transformations along the normality test p-value for said transformations.

\includegraphics{images/analysis3_2_2.png}

By clicking the ``Show false'' button, all the non normal exposures are listed with the method that will be applied to normalize, this table can be edited (the ``Normalization method'' column) by double clicking on the desired row. There are three possible methods to use, ``log'' (default, natural logarithm), ``\^{}1/3'' and ``sqrt''. If no method is desired to be applied to an exposure (keep the original variable) input ``none''. The normalization method refers to applying X function to a column of the exposures tables, to transform it.

\includegraphics{images/analysis3_3.png}

Click ``Normalize'' and the normalization method selected will be applied, the table on the ``Check Normality'' tab will be updated with the results of the normalization.

\hypertarget{exposures-description-1}{%
\subsection{Exposures description}\label{exposures-description-1}}

\includegraphics{images/analysis4_1.png}

To see all the insights of the exposures dataset loaded into the Shiny, once loaded it check the exposures description tab, there are three options to dig into the dataset, the family (family of the exposure) to visualize and two grouping factors (phenotypes).

\includegraphics{images/analysis4_2.png}

\hypertarget{pca-analysis}{%
\subsection{PCA Analysis}\label{pca-analysis}}

\includegraphics{images/analysis5_1.png}

To see the results of a PCA (principal component analysis) study, load the data and check the PCA Visualization tab, there a set and grouping factor can be choose, it's important noting (as it's already stated on the Shiny) that the grouping parameter only works when the set is selected to ``samples''. There are also selectors to choose which principal component to visualize on each axis, 10 principal components are computed.

\includegraphics{images/analysis5_2.png}

If the association of the PCA analysis with the exposures is desired to visualize, check the ``PCA association with exposures'' tab, there are two grouping methods to visualize, the phenotypes to principal components and the exposures to principal components.

\includegraphics{images/analysis5_3.png}

By clicking on ``Visualize as table'', the table corresponding to the selected association will be prompted on a pop-up window, this table can be downloaded as a csv.

\includegraphics{images/analysis5_3_2.png}

\hypertarget{clusterization-and-correlation-of-exposures}{%
\subsection{Clusterization and correlation of exposures}\label{clusterization-and-correlation-of-exposures}}

Displaying the correlation of the exposures can help to visualize intra and inter family relations between the exposures, for that reason there are two different visualization options, the circos and the matrix.

The clusterization of exposures uses a hierarchical clustering algorithm to classify the individuals profiles of exposures in k groups, where k can be selected by the user. The plot shows the profile for each group of individuals.

\includegraphics{images/analysis6_1.png}

To see the results of the exposure correlation and clustering, select the corresponding tab to each analysis. For the exposure correlation analysis there are two visualizations, the matrix representation and the circos. The correlation uses Pearson method for numerical-to-numerical correlation, Cramer's V for categorical-to-categorical correlation and linear models for categorical-to-numerical.

\includegraphics{images/analysis6_2.png}

\includegraphics{images/analysis6_3.png}

\includegraphics{images/analysis6_4.png}

\hypertarget{exwas}{%
\subsection{ExWAS}\label{exwas}}

\includegraphics{images/analysis7_1.png}

\hypertarget{regular}{%
\subsubsection{Regular}\label{regular}}

To perform an ExWAS (exposome-wide association, univariate test of the association between exposures and health outcomes using generalized linear models) study, check the ExWAS tab and select the addecuate parameters for the ExWAS plot, there are two different plot representations, the output variable to choose (phenotype), the output family and as many covariables (phenotypes) as the user wants. There are internal checks to advise the user on which parameters to select depending if the selected outcome is numerical or bionomial.

\includegraphics{images/analysis7_2.png}

\hypertarget{stratified}{%
\subsubsection{Stratified}\label{stratified}}

There is an option to perform a stratified ExWAS, to do so, check the toggle ``Stratified analysis'', this will display a new input field to select a categorical phenotype to stratify by. This analysis will yield as many ExWAS plots as levels has the category selected, when downloading the table of results for a stratified analysis, a \emph{.zip} file will be downloaded with a table corresponding to each plot. The naming of the tables corresponds to the stratifying variable with the category name attached (\texttt{sex\_female.csv} / \texttt{sex\_male.csv} in the presented case).

\includegraphics{images/analysis7_7.png}

\hypertarget{exwas---ctdquerier}{%
\subsection{ExWAS - CTDquerier}\label{exwas---ctdquerier}}

The ExWAS tab also is able to perform a CTD query of the desired chemicals.

\includegraphics{images/analysis7_3.png}

To perform a CTDquerier of chemicals with the results of the ExWAS, click on the desired exposure to preload it into the query, when clicked, a chemical name with it's associated P-Value will appear on the table on the right, if that's the desired chemical to add to the query list click ``Add to querier''. In the case of adding an unwanted chemical to the query list, select it (or them) by clicking on the Querier list and click on ``Remove from querier''.

\includegraphics{images/analysis7_4.png}

\includegraphics{images/analysis7_5.png}

To do the query of the chemicals to de CTD database click on ``Query on the CTD gene database'' and see the results on the ``Chemical CTDquerier Results'' subtab. It's important noting that on the ``Kegg pathways'' and ``Go terms'' the input field corresponds to the negative exponent of the filter.

\includegraphics{images/analysis7_6.png}

\hypertarget{multivariate-exwas}{%
\subsection{Multivariate ExWAS}\label{multivariate-exwas}}

Multivariate analysis using Elastic Net (LASSO regression). Multivariate ExWAS applies elastic net to the exposures given a health outcome of interest. The heat map is coloured with the coefficient of each exposure in relation with the health outcome, so the ones in white are not interesting. The two columns of the heat map correspond to the minimum lambda (\texttt{Min}) and to the lambda which gives the most regularised model such that error is within one standard error of the minimum (\texttt{1SE}).

\includegraphics{images/analysis8_1.png}

To perform a multivariate ExWAS study, check the Multivariate ExWAS tab and select the desired output parameter, click on run model to generate the plot. As on the ExWAS plot options there's implemented an internal check to advise the user on which parameters to select depending if the selected outcome is numerical or bionomial, as the diagrams states if the dataset has not been imputed the missings, it will automatically do it to perform the Multivariate ExWAS, however when closing the plot the imputed dataset will be removed from the environment, so all the other studies performed afterwards will not be altered.

\includegraphics{images/analysis8_2.png} \includegraphics{images/analysis8_3.png}

\hypertarget{exposome-omic-analysis}{%
\section{Exposome-Omic analysis}\label{exposome-omic-analysis}}

It's important noting that the maximum size of the omics data is 30 MB, if the omics file to be analyzed is bigger, change the line number 2 of the \texttt{server.R} file.

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# the "30" refers to 30MB, change as needed}
\FunctionTok{options}\NormalTok{(}\AttributeTok{shiny.maxRequestSize=}\DecValTok{30}\SpecialCharTok{*}\DecValTok{1024}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{association-analysis}{%
\subsection{Association analysis}\label{association-analysis}}

\includegraphics{images/analysis9_1.png}

Do first the proceeding of exposome data load and corresponding treatment if desired, then proceed to load the omic dataset on the ``Data Entry'' subtab. The omic data should be provided as a \texttt{*.RData} file.

\includegraphics{images/analysis9_2.png}

The exposome dataset can be subseted by families for this analysis, on the ``Exposome subsetting'' subtab select the families that are desired to be included in this new set to study, if all the families are desired just don't input any and proceed to click the ``Subset and add'', which will trigger the action to combine the subsetted (or not) exposome dataset with the provided omic dataset.

\includegraphics{images/analysis9_3.png}

Select the variables for the association analysis (linear models) and if SVA (surrogate variable analysis) is wanted on the ``Association model'' subtab.

\includegraphics{images/analysis9_4.png}

There are tabs to visualize the results of running the association model, all of the are on the ``Model visualization'' subtab. The ``Results table'' shows the gene, log of the fold change, p-value and adjusted p-value.

\includegraphics{images/analysis9_5.png}

The ``Significant hits'' shows the exposure, hits and lambda.

\includegraphics{images/analysis9_6.png}

The QQ Plot shows a QQ plot (expected vs.~observed -lo10(p-value)) for the selected exposure.

\includegraphics{images/analysis9_7.png}

The Volcan plot shows a volcano plot (log2(fold change) vs -log10(p-value)). For this plot there are two input cells to adjust the horizontal and verital limit lines to filter out the results.

\includegraphics{images/analysis9_8.png}

\hypertarget{ctd-querier}{%
\subsection{CTD querier}\label{ctd-querier}}

\includegraphics{images/analysis10_1.png}

To perform a CTD querier study of the exposome-omic association analysis, as before, load both datasets and run the desired model with them, check the Volcano plot and click on the desired point on the Volcano plot, the information of the selected plot will appear on the table below the plot (sometimes there are many points close so more than one rows can appear on the table), select from the table the desired point to add to the query and click ``Add to querier''. It's important noting that when trying to add to the querier the Shiny will find on the fields of the omic dataset that the user specifies on top of the plot. If the search does not return any symbol a prompt will appear, however if it's found it will be added to the lower table corresponding to the genes to query.

\includegraphics{images/analysis10_2.png}

If by mistake some gene (or genes) were introduced to the querier, select them by clicking on the table row and click ``Remove from querier''. Go to the CTDquerier tab to perform the query with the selected genes.

\includegraphics{images/analysis10_3.png}

There are six tabs showing different results interpretations. First there's the ``Lost \& found'' tab which a plot to see the amount of genes found on the CTD database and the ones that were not found them, ther's also two lists stating the names of them.

\includegraphics{images/analysis10_4.png}

The diseases tab shows a table of all the associated diseases found on the CTD database.

\includegraphics{images/analysis10_5.png}

The curated diseases tab shows the table of associated diseases but only shows the ones with direct evidence.

\includegraphics{images/analysis10_6.png}

The association tab shows information about all the direct evidence associated diseases. Select the disease of interest to see the score and reference count of it.

\includegraphics{images/analysis10_7.png}

The inference score tab shows the inference score for each gene for a selected disease, the filter parameters puts out the genes with an inference score lower than the selected filter.

\includegraphics{images/analysis10_8.png}

The association matrix tab shows a matrix of genes vs.~chemicals with a heatmap representing the existing papers (references) providing evidence about the association between chemicals and genes.

\includegraphics{images/analysis10_9.png}

\hypertarget{enrichment-analysis}{%
\subsection{Enrichment analysis}\label{enrichment-analysis}}

\includegraphics{images/analysis11.png}

To perform an enrichment analysis, the genes of interest have to ve selected as with the CTDquerier, using the volcano plot from the association analysis.

\includegraphics{images/analysis10_2.png}

After selecting them, go to the ``Enrichment analysis'' tab, on it there is a selector to choose between GO and KEGG databases and a threshold selector for the cutoff pvalue of the enrichment analysis.

\includegraphics{images/analysis11_1.png}

When the enrichment analysis is performed, there are multiple visualization tabs for the results, the first one is a table with the plain results, which can be downloaded.

\includegraphics{images/analysis11_2.png}

The following four tabs correspond to different visualization options for the results. All of them can be downloaded.

\includegraphics{images/analysis11_3.png}
\includegraphics{images/analysis11_4.png}
\includegraphics{images/analysis11_5.png}
\includegraphics{images/analysis11_6.png}

\hypertarget{exposome-omic-intregration-e.g.-crossomics}{%
\section{Exposome-Omic intregration (e.g.~crossomics)}\label{exposome-omic-intregration-e.g.-crossomics}}

\includegraphics{images/analysis12.png}

The relation between exposures and omic-features can be studied from another perspective, different from the association analyses. The integration analysis can be done, using multi canonical correlation analysis ,multiple co-inertia analysis or partial least squares (this method only is supported with one omics dataset). The first methods is implemented in R package \texttt{PMA} (CRAN) and the second in \texttt{omicade4} R package (Bioconductor). The PLS uses the \texttt{pls} R package (CRAN).

For the MCIA and MCCA options, the exposome dataset can't contain missings, so it needs to be imputed beforehand. For the PLS there can be missings, however the integration analysis is done with complete cases only. Also different visualizations are provided for each method, as the used R packages provide different visualization tools, all three methods generate different type of R objects, which can be downloaded to be explorated by the user on a separate R session.

The differences between association and crossomics are that the first method test association between two complete data-sets, by removing the samples having missing values in any of the involved data-sets, and the second try to find latent relationships between two or more sets.

The following screenshots correspond to integration analysis using the exposome dataset \texttt{data/*\_2} and the proteome omics dataset \texttt{data/brge\_prot.rda}. (Exposome imputed inside exposomeShiny using MICE)

\includegraphics{images/analysis12_1.png}

\includegraphics{images/analysis12_2.png}

\includegraphics{images/analysis12_3.png}

\hypertarget{general-application-functionalities}{%
\chapter{General application functionalities}\label{general-application-functionalities}}

This whole Shiny application serves the purpose to perform a various number of exposome and omic analysis with an input set of data. To perform this analysis some operations can performed on the inputed dataset prior to the analysis and so in order to follow track of what exactly has been done or what is loaded on the current session, there's implemented some sort of state tracker inside the Shiny application. In order to access it, press the icon on the top right of the application

\includegraphics{images/general1.png}

When clicking it a dropdown menu appears, inside there are seven different notifications:

\begin{itemize}
\tightlist
\item
  Exposome dataset: Turns to 100\% when an exposome dataset is loaded in the environment. Here's a graphical example.

  \includegraphics{images/general2.png}

  \includegraphics{images/general3.png}
\item
  LOD imputed: Turns to 100\% if the exposome dataset is LOD imputed.
\item
  Missing imputed: Turns to 100\% if the exposome dataset has the missings imputed.
\item
  Normality corrected: Turns to 100\% if the exposome dataset is normality corredted.
\item
  Omics dataset: Turns to 100\% when an omics dataset is loaded in the environment.
\item
  Subset: Turns to 100\% (and displays the subset family(ies)) when the exposome dataset is subseted.
\item
  Model: Turns to 100\% (and displays the association variable(s)) when a model is performed for an omics association analysis. Here's an example of a subset and model information.

  \includegraphics{images/general4.png}
\end{itemize}

\hypertarget{methods}{%
\chapter{Methods}\label{methods}}

\hypertarget{missing-data-imputation}{%
\section{Missing data imputation}\label{missing-data-imputation}}

LOD missings are discovered through a encoding provided by the user, there is no method implemented to separate missing values between missing at random at LOD, meaning that all NA values are considered missing at random.

\hypertarget{limit-of-detection-lod-missing}{%
\subsection{Limit of detection (LOD) missing}\label{limit-of-detection-lod-missing}}

LOD missings can be imputed using two methodologies:

\begin{itemize}
\tightlist
\item
  LOD value / sqrt(2) : Use a LOD value provided by the user (one value per exposures) divided by the square root of two. \citet{Richardson2003}
\item
  QRILC: a quantile regression approach for the imputation of left-censored missing data \citet{lod_impute}.
\end{itemize}

\hypertarget{missing-at-random}{%
\subsection{Missing at random}\label{missing-at-random}}

Multiple imputation chained equations (MICE) is used to impute missing at random data. The \emph{mice} package is used to do so. A brief explanation on the algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Imputation of the variable (exposure) xn with the mean of all it's values.
\item
  Perform 1 for all the variables.
\item
  Set the mean imputed values from one variable back to missing.
\item
  Perform a regression model and fill those missings.
\item
  Repeat 3 and 4 for all the variables.
\item
  Repeat 3, 4 and 5 until the imputed values obtained are stabilized.
\end{enumerate}

\hypertarget{normality}{%
\section{Normality}\label{normality}}

\hypertarget{normality-testing}{%
\subsection{Normality testing}\label{normality-testing}}

To test the normality of a variable, a Shapiro-Wilks test is used. The Shapiro-Wilks test, tests the null hypothesis of a sample (variable of the dataset) is normally distributed, to perform the test it calculates the W statistic.

\(W = \frac{\left( \Sigma^{n}_{i=1} a_i x_{(i)} \right)^2}{\Sigma^{n}_{i=1} (x_i - \overline{x})^2}\)

To perform this test exposome uses the \emph{shapiro.test} function from the \emph{base} package of R.

\hypertarget{normalization}{%
\subsection{Normalization}\label{normalization}}

A user selected function can be applied to exposures (selected by the user) to normalize them. The available functions are: \emph{log}, \emph{sqrt} and \emph{\^{}1/3}.

\hypertarget{principal-component-analysis-pca}{%
\section{Principal component analysis (PCA)}\label{principal-component-analysis-pca}}

Rexposome contains two PCA methodologies

\begin{itemize}
\tightlist
\item
  Regular PCA \citet{Jolliffe2016} (only numerical exposures)
\item
  FAMD \citet{chavent2014multivariate} (numerical and categorical)
\end{itemize}

exposomeShiny uses regular PCA from the \emph{FactoMineR} package. A toggle to select between the two may be added in future releases.

\hypertarget{exposures-correlation}{%
\section{Exposures correlation}\label{exposures-correlation}}

The correlation method takes into account the nature of each pair of exposures: continuous vs.~continuous uses cor function from R \emph{base}, categorical vs.~categorical uses cramerV function from \emph{lsr} R package and categorical vs.~continuous exposures correlation is calculated as the square root of the adjusted r-square obtained from fitting a lineal model with the categorical exposures as dependent variable and the continuous exposure as independent variable.

\hypertarget{exposures-clustering}{%
\section{Exposures clustering}\label{exposures-clustering}}

Clustering analysis on samples can be performed to cluster individuals having similar exposure profiles. This is done using hierarchical clustering using the function \emph{hclust} from the \emph{stats} R package. The results this analysis yields are the exposure profiles of a selected number of groups.

\hypertarget{exposome-association-analysis}{%
\section{Exposome Association Analysis}\label{exposome-association-analysis}}

\hypertarget{single-association-analysis}{%
\subsection{Single Association Analysis}\label{single-association-analysis}}

Exposome-Wide Association Study (ExWAS) is equivalent to a Genome-Wide Association Study (GWAS) in genomics or to Epigenetic-Wide Association Study (EWAS) in epigenomics. The ExWAS was first described by Patel et al. \citet{patel2010environment} . ExWAS are based on generalized linear models using any formula describing the model that should be adjusted for (following standard formula options in R). That is, continuous or factor variables can be incorporated in the design, as well as interaction or splines using standard R functions and formulas. Multiple comparisons in the ExWAS analysis is addressed by computing the number of effective (Neff) tests as described by Li and Ju \citet{li2005adjusting} . The method estimates Neff by using the exposure correlation matrix that is corrected when it is not positive definite by using \emph{nearPD} R function. The significant threshold is computed as 1-(1-0.05)Meff. This threshold is added to the Manhattan plots. When using imputed data, analysis is done for each imputed set and P-Values are pooled to obtain a global association score.

\hypertarget{stratified-single-association-analysis}{%
\subsection{Stratified Single Association Analysis}\label{stratified-single-association-analysis}}

The stratified analysis option for the ExWAS corresponds to applying the same method as regular ExWAS to subsetted datasets. As example, a stratified analysis with the \texttt{sex} variable stratified corresponds to performing two ExWAS, one to the \texttt{male} and one for the \texttt{female} group.

\hypertarget{multivariate-association-analysis}{%
\subsection{Multivariate Association Analysis}\label{multivariate-association-analysis}}

There are some authors that proposed to perform association analysis in a multivariate fashion, just to take into account the correlation across exposures \citet{agier2016systematic} . A Lasso regression is implemented using Elastic-Net regularized generalized linear models implemented in \emph{glmnet} R package.

\hypertarget{exposome-omic-association-analysis}{%
\section{Exposome-Omic Association Analysis}\label{exposome-omic-association-analysis}}

Perform association analyses between exposures and omic data bt fitting linear models as described in the \emph{limma} R package \citet{ritchie2015limma} . The pipeline implemented in association allows performing surrogate variable analysis in order to correct for unwanted variability. This adjustment is provided by \emph{SVA} R package \citet{sva} .

\hypertarget{integration-analysis}{%
\section{Integration analysis}\label{integration-analysis}}

There are three different methodologies to perform the integration analysis:

\begin{itemize}
\tightlist
\item
  Multiset canonical correlation analysis (MCCA). Implemented using the \texttt{MultiCCA} function of \texttt{PMA} R package \citet{witten2020package} .
\item
  Multiple co-inertia analysis (MCIA). Implemented using the \texttt{mcia} function of \texttt{omicade4} R package \citet{mcia} , \citet{min2020sparse} .
\item
  Partial least squares (PLS)
\end{itemize}

\hypertarget{enrichment-analysis-1}{%
\section{Enrichment analysis}\label{enrichment-analysis-1}}

Functional profiles of selected genes are obtained using the Bioconductor package \texttt{clusterProfiler} \citet{clusterprofiler} . The available enrichment databases are GO and KEGG.

\hypertarget{references}{%
\chapter{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{0}{0}
\end{CSLReferences}

  \bibliography{book.bib,packages.bib}

\end{document}
